{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2.6. Intro to TensorFlow and Keras\n",
    "\n",
    "Original code in Nikolenko book was made in **TensorFlow 1.x (TF1)**, but here I will convert examples to **TensorFlow 2.0 (TF2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T14:28:48.525489Z",
     "start_time": "2019-11-17T14:28:47.547630Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Regression using TensorFlow 2\n",
    "\n",
    "$$y = k_{true} * x + b_{true} + \\epsilon$$\n",
    "\n",
    "$$\\epsilon - normal noise (N(0, 2))$$\n",
    "\n",
    "Let's try to recover coefs `k_true`, `b_true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T14:28:49.863337Z",
     "start_time": "2019-11-17T14:28:49.739705Z"
    }
   },
   "outputs": [],
   "source": [
    "# set constants\n",
    "n_samples = 1000\n",
    "batch_size = 100\n",
    "num_steps = 2000\n",
    "display_step = 100\n",
    "\n",
    "k_true = 2\n",
    "b_true = 1\n",
    "\n",
    "# generate data\n",
    "X_data = np.random.uniform(1,10,(n_samples, 1))\n",
    "y_data = k_true * X_data + b_true + np.random.normal(0, 2, (n_samples, 1))\n",
    "\n",
    "# initialize coefs\n",
    "k = tf.Variable(tf.random.normal((1,1), dtype='float64'), name='slope')\n",
    "b = tf.Variable(tf.zeros((1,), dtype='float64'), name='bias')\n",
    "\n",
    "\n",
    "# create model class\n",
    "class MyModel():\n",
    "    \n",
    "    def __init__(self, k, b):\n",
    "        self.k = k\n",
    "        self.b = b\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        return tf.matmul(X, self.k) + self.b\n",
    "    \n",
    "# define loss\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "\n",
    "# define forward step\n",
    "def train(model, X, y, optimizer):\n",
    "    \"\"\"\n",
    "    One step of optimization\n",
    "    \n",
    "    params:\n",
    "        model: model object ot train\n",
    "        X: data\n",
    "        y: target \n",
    "    return:\n",
    "        loss: loss value\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as t:\n",
    "        y_pred = model(X)\n",
    "        loss = mse_loss(y, y_pred)\n",
    "        \n",
    "    grads = t.gradient(loss, [model.k, model.b])\n",
    "    optimizer.apply_gradients(zip(grads,[model.k, model.b]))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T14:28:52.557700Z",
     "start_time": "2019-11-17T14:28:50.655889Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: loss=405.2075125448249, k=[[2.03974921]], b=[0.48782402]\n",
      "Epoch 200: loss=432.12792702674767, k=[[2.03229947]], b=[0.67374956]\n",
      "Epoch 300: loss=423.07094733658084, k=[[2.00657784]], b=[0.79454969]\n",
      "Epoch 400: loss=403.640519587412, k=[[2.04567009]], b=[0.88216861]\n",
      "Epoch 500: loss=379.5927577813817, k=[[2.00102378]], b=[0.91664975]\n",
      "Epoch 600: loss=499.99162499952297, k=[[1.99153073]], b=[0.95919205]\n",
      "Epoch 700: loss=367.5354460205415, k=[[2.00231788]], b=[0.99361275]\n",
      "Epoch 800: loss=367.7656598664735, k=[[1.98794238]], b=[1.02533584]\n",
      "Epoch 900: loss=360.83962584540876, k=[[2.01658998]], b=[1.00642175]\n",
      "Epoch 1000: loss=339.1165403425979, k=[[1.95835814]], b=[1.00355341]\n",
      "Epoch 1100: loss=320.84698288482485, k=[[1.97359641]], b=[0.99783332]\n",
      "Epoch 1200: loss=513.1217162002757, k=[[1.97291515]], b=[1.00958784]\n",
      "Epoch 1300: loss=382.31173302154235, k=[[1.97768824]], b=[0.99861147]\n",
      "Epoch 1400: loss=408.0682098660934, k=[[2.0017979]], b=[1.04160361]\n",
      "Epoch 1500: loss=407.6285016343411, k=[[1.97425484]], b=[1.02376875]\n",
      "Epoch 1600: loss=416.10430374450686, k=[[2.00405758]], b=[1.02971641]\n",
      "Epoch 1700: loss=404.2391723648843, k=[[1.99118556]], b=[0.99011072]\n",
      "Epoch 1800: loss=465.8338022450782, k=[[1.99577623]], b=[1.00210319]\n",
      "Epoch 1900: loss=430.3975773983506, k=[[1.9692536]], b=[0.98217716]\n",
      "Epoch 2000: loss=432.3023582816821, k=[[1.94853832]], b=[0.96249335]\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.SGD(learning_rate=1e-4)\n",
    "model = MyModel(k, b)\n",
    "\n",
    "# running optimization\n",
    "for i in range(num_steps):\n",
    "    \n",
    "    # select data batch\n",
    "    indices = np.random.choice(n_samples, batch_size)\n",
    "    X_batch, y_batch = X_data[indices], y_data[indices]\n",
    "    \n",
    "    loss_val = train(model, X_batch, y_batch, optimizer)\n",
    "    \n",
    "    # output info\n",
    "    if (i+1) % display_step == 0:\n",
    "        print(f'Epoch {i+1}: loss={loss_val}, k={model.k.numpy()}, b={model.b.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got approximate values `k = 1.94` and `b = 0.96`.\n",
    "\n",
    "\n",
    "## 2. Logistic Regression using TF2 Keras api\n",
    "\n",
    "- Generate some data;\n",
    "- Define simple logistic regression (1 dense layer with sigmoid activation);\n",
    "- Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T14:52:49.319740Z",
     "start_time": "2019-11-17T14:52:49.312458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2) (2000, 1)\n",
      "(200, 2) (200, 1)\n"
     ]
    }
   ],
   "source": [
    "def sampler(n, x, y):\n",
    "    return np.random.normal(size=[n,2]) + [x, y]\n",
    "\n",
    "def sample_data(n=1000, p0=(-1., -1.), p1=(1., 1.)):\n",
    "    zeros, ones = np.zeros((n, 1)), np.ones((n, 1))\n",
    "    labels = np.vstack([zeros, ones])\n",
    "    \n",
    "    z_sample = sampler(n, x=p0[0], y=p0[1])\n",
    "    o_sample = sampler(n, x=p1[0], y=p1[1])\n",
    "    \n",
    "    return np.vstack([z_sample, o_sample]), labels\n",
    "\n",
    "X_train, Y_train = sample_data()\n",
    "X_test, Y_test = sample_data(100)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T15:00:39.209037Z",
     "start_time": "2019-11-17T15:00:39.204754Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = tf.keras.Sequential(\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    ")\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T14:57:23.854131Z",
     "start_time": "2019-11-17T14:57:22.891986Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 200 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 0s 12us/sample - loss: 0.1973 - accuracy: 0.9225 - val_loss: 0.1826 - val_accuracy: 0.9400\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1973 - accuracy: 0.9225 - val_loss: 0.1826 - val_accuracy: 0.9400\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1973 - accuracy: 0.9225 - val_loss: 0.1825 - val_accuracy: 0.9400\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1972 - accuracy: 0.9225 - val_loss: 0.1825 - val_accuracy: 0.9400\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 0s 10us/sample - loss: 0.1972 - accuracy: 0.9225 - val_loss: 0.1824 - val_accuracy: 0.9400\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1972 - accuracy: 0.9225 - val_loss: 0.1824 - val_accuracy: 0.9400\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1972 - accuracy: 0.9225 - val_loss: 0.1823 - val_accuracy: 0.9450\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1971 - accuracy: 0.9225 - val_loss: 0.1823 - val_accuracy: 0.9450\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1971 - accuracy: 0.9225 - val_loss: 0.1822 - val_accuracy: 0.9450\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1971 - accuracy: 0.9225 - val_loss: 0.1822 - val_accuracy: 0.9450\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1971 - accuracy: 0.9225 - val_loss: 0.1821 - val_accuracy: 0.9450\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1970 - accuracy: 0.9225 - val_loss: 0.1821 - val_accuracy: 0.9450\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1970 - accuracy: 0.9225 - val_loss: 0.1820 - val_accuracy: 0.9450\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1970 - accuracy: 0.9225 - val_loss: 0.1820 - val_accuracy: 0.9450\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1970 - accuracy: 0.9225 - val_loss: 0.1819 - val_accuracy: 0.9450\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1969 - accuracy: 0.9225 - val_loss: 0.1819 - val_accuracy: 0.9450\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1969 - accuracy: 0.9225 - val_loss: 0.1818 - val_accuracy: 0.9450\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1969 - accuracy: 0.9225 - val_loss: 0.1818 - val_accuracy: 0.9450\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1969 - accuracy: 0.9225 - val_loss: 0.1818 - val_accuracy: 0.9450\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1969 - accuracy: 0.9225 - val_loss: 0.1817 - val_accuracy: 0.9450\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1968 - accuracy: 0.9225 - val_loss: 0.1817 - val_accuracy: 0.9450\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1968 - accuracy: 0.9225 - val_loss: 0.1816 - val_accuracy: 0.9450\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1968 - accuracy: 0.9225 - val_loss: 0.1816 - val_accuracy: 0.9450\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1968 - accuracy: 0.9225 - val_loss: 0.1815 - val_accuracy: 0.9450\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1968 - accuracy: 0.9225 - val_loss: 0.1815 - val_accuracy: 0.9450\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1967 - accuracy: 0.9225 - val_loss: 0.1815 - val_accuracy: 0.9450\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 0s 8us/sample - loss: 0.1967 - accuracy: 0.9225 - val_loss: 0.1814 - val_accuracy: 0.9450\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1967 - accuracy: 0.9225 - val_loss: 0.1814 - val_accuracy: 0.9450\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1967 - accuracy: 0.9225 - val_loss: 0.1813 - val_accuracy: 0.9450\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 0s 10us/sample - loss: 0.1967 - accuracy: 0.9225 - val_loss: 0.1813 - val_accuracy: 0.9450\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1966 - accuracy: 0.9225 - val_loss: 0.1813 - val_accuracy: 0.9450\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1966 - accuracy: 0.9225 - val_loss: 0.1812 - val_accuracy: 0.9450\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1966 - accuracy: 0.9225 - val_loss: 0.1812 - val_accuracy: 0.9450\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1966 - accuracy: 0.9225 - val_loss: 0.1811 - val_accuracy: 0.9450\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1966 - accuracy: 0.9225 - val_loss: 0.1811 - val_accuracy: 0.9450\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1965 - accuracy: 0.9225 - val_loss: 0.1811 - val_accuracy: 0.9450\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1965 - accuracy: 0.9225 - val_loss: 0.1810 - val_accuracy: 0.9450\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1965 - accuracy: 0.9225 - val_loss: 0.1810 - val_accuracy: 0.9450\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1965 - accuracy: 0.9225 - val_loss: 0.1810 - val_accuracy: 0.9450\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1965 - accuracy: 0.9225 - val_loss: 0.1809 - val_accuracy: 0.9450\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 0s 10us/sample - loss: 0.1965 - accuracy: 0.9225 - val_loss: 0.1809 - val_accuracy: 0.9450\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1964 - accuracy: 0.9225 - val_loss: 0.1809 - val_accuracy: 0.9450\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1964 - accuracy: 0.9225 - val_loss: 0.1808 - val_accuracy: 0.9450\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1964 - accuracy: 0.9225 - val_loss: 0.1808 - val_accuracy: 0.9450\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1964 - accuracy: 0.9225 - val_loss: 0.1807 - val_accuracy: 0.9450\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1964 - accuracy: 0.9225 - val_loss: 0.1807 - val_accuracy: 0.9450\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1964 - accuracy: 0.9225 - val_loss: 0.1807 - val_accuracy: 0.9450\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1963 - accuracy: 0.9225 - val_loss: 0.1806 - val_accuracy: 0.9450\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1963 - accuracy: 0.9225 - val_loss: 0.1806 - val_accuracy: 0.9450\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 0s 9us/sample - loss: 0.1963 - accuracy: 0.9225 - val_loss: 0.1806 - val_accuracy: 0.9450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f12002a17f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=128, validation_data=(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
