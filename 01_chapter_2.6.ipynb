{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2.6. Intro to TensorFlow and Keras\n",
    "\n",
    "Original code in Nikolenko book was made in **TensorFlow 1.x (TF1)**, but here I will convert examples to **TensorFlow 2.0 (TF2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T15:07:37.559977Z",
     "start_time": "2019-11-17T15:07:36.564376Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Regression using TensorFlow 2\n",
    "\n",
    "$$y = k_{true} * x + b_{true} + \\epsilon$$\n",
    "\n",
    "$$\\epsilon - normal noise (N(0, 2))$$\n",
    "\n",
    "Let's try to recover coefs `k_true`, `b_true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T15:07:38.775304Z",
     "start_time": "2019-11-17T15:07:38.612315Z"
    }
   },
   "outputs": [],
   "source": [
    "# set constants\n",
    "n_samples = 1000\n",
    "batch_size = 100\n",
    "num_steps = 2000\n",
    "display_step = 100\n",
    "\n",
    "k_true = 2\n",
    "b_true = 1\n",
    "\n",
    "# generate data\n",
    "X_data = np.random.uniform(1,10,(n_samples, 1))\n",
    "y_data = k_true * X_data + b_true + np.random.normal(0, 2, (n_samples, 1))\n",
    "\n",
    "# initialize coefs\n",
    "k = tf.Variable(tf.random.normal((1,1), dtype='float64'), name='slope')\n",
    "b = tf.Variable(tf.zeros((1,), dtype='float64'), name='bias')\n",
    "\n",
    "\n",
    "# create model class\n",
    "class MyModel():\n",
    "    \n",
    "    def __init__(self, k, b):\n",
    "        self.k = k\n",
    "        self.b = b\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        return tf.matmul(X, self.k) + self.b\n",
    "    \n",
    "# define loss\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "\n",
    "# define forward step\n",
    "def train(model, X, y, optimizer):\n",
    "    \"\"\"\n",
    "    One step of optimization\n",
    "    \n",
    "    params:\n",
    "        model: model object ot train\n",
    "        X: data\n",
    "        y: target \n",
    "    return:\n",
    "        loss: loss value\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as t:\n",
    "        y_pred = model(X)\n",
    "        loss = mse_loss(y, y_pred)\n",
    "        \n",
    "    grads = t.gradient(loss, [model.k, model.b])\n",
    "    optimizer.apply_gradients(zip(grads,[model.k, model.b]))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T15:07:41.341918Z",
     "start_time": "2019-11-17T15:07:39.457780Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: loss=328.4014782744676, k=[[2.0347777]], b=[0.45696314]\n",
      "Epoch 200: loss=441.4016353059742, k=[[2.03287446]], b=[0.61575231]\n",
      "Epoch 300: loss=428.30945380147494, k=[[2.07178783]], b=[0.74163124]\n",
      "Epoch 400: loss=424.43686321990606, k=[[2.04131705]], b=[0.82955066]\n",
      "Epoch 500: loss=335.6280162414797, k=[[1.99352792]], b=[0.87748055]\n",
      "Epoch 600: loss=371.01780966592855, k=[[1.98934505]], b=[0.95281984]\n",
      "Epoch 700: loss=412.8920851745517, k=[[2.02760397]], b=[0.99698293]\n",
      "Epoch 800: loss=408.2759653164994, k=[[2.06301567]], b=[1.00223127]\n",
      "Epoch 900: loss=432.59193086789526, k=[[1.97749149]], b=[1.01195023]\n",
      "Epoch 1000: loss=516.9335502605454, k=[[2.00373984]], b=[1.01602768]\n",
      "Epoch 1100: loss=381.3437039336857, k=[[2.03720823]], b=[1.00947445]\n",
      "Epoch 1200: loss=375.30038921320687, k=[[1.96749361]], b=[1.00676618]\n",
      "Epoch 1300: loss=386.22566716969754, k=[[2.01734126]], b=[1.02658512]\n",
      "Epoch 1400: loss=446.9548052102519, k=[[2.02009147]], b=[1.04640993]\n",
      "Epoch 1500: loss=332.3382147063178, k=[[1.95003441]], b=[1.03099182]\n",
      "Epoch 1600: loss=382.75203615514135, k=[[1.94277831]], b=[1.03180882]\n",
      "Epoch 1700: loss=345.6776092906766, k=[[1.99071091]], b=[1.05298186]\n",
      "Epoch 1800: loss=486.43837863390553, k=[[1.98387549]], b=[1.04419106]\n",
      "Epoch 1900: loss=443.4270241598496, k=[[1.98099689]], b=[1.04163539]\n",
      "Epoch 2000: loss=394.0435149488167, k=[[1.97925961]], b=[1.03796941]\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.SGD(learning_rate=1e-4)\n",
    "model = MyModel(k, b)\n",
    "\n",
    "# running optimization\n",
    "for i in range(num_steps):\n",
    "    \n",
    "    # select data batch\n",
    "    indices = np.random.choice(n_samples, batch_size)\n",
    "    X_batch, y_batch = X_data[indices], y_data[indices]\n",
    "    \n",
    "    loss_val = train(model, X_batch, y_batch, optimizer)\n",
    "    \n",
    "    # output info\n",
    "    if (i+1) % display_step == 0:\n",
    "        print(f'Epoch {i+1}: loss={loss_val}, k={model.k.numpy()}, b={model.b.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got approximate values `k = 1.97` and `b = 1.03`.\n",
    "\n",
    "\n",
    "## 2. Logistic Regression using TF2 Keras api\n",
    "\n",
    "- Generate some data;\n",
    "- Define simple logistic regression (1 dense layer with sigmoid activation);\n",
    "- Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T15:07:57.105300Z",
     "start_time": "2019-11-17T15:07:57.097918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2) (2000, 1)\n",
      "(200, 2) (200, 1)\n"
     ]
    }
   ],
   "source": [
    "# generate data\n",
    "def sampler(n, x, y):\n",
    "    return np.random.normal(size=[n,2]) + [x, y]\n",
    "\n",
    "def sample_data(n=1000, p0=(-1., -1.), p1=(1., 1.)):\n",
    "    zeros, ones = np.zeros((n, 1)), np.ones((n, 1))\n",
    "    labels = np.vstack([zeros, ones])\n",
    "    \n",
    "    z_sample = sampler(n, x=p0[0], y=p0[1])\n",
    "    o_sample = sampler(n, x=p1[0], y=p1[1])\n",
    "    \n",
    "    return np.vstack([z_sample, o_sample]), labels\n",
    "\n",
    "X_train, Y_train = sample_data()\n",
    "X_test, Y_test = sample_data(100)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T15:07:59.726402Z",
     "start_time": "2019-11-17T15:07:59.707414Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = tf.keras.Sequential(\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    ")\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T15:08:05.533734Z",
     "start_time": "2019-11-17T15:08:00.461687Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 200 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 0s 204us/sample - loss: 0.2649 - accuracy: 0.9180 - val_loss: 0.2683 - val_accuracy: 0.9000\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 0s 45us/sample - loss: 0.2479 - accuracy: 0.9205 - val_loss: 0.2555 - val_accuracy: 0.9000\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 0s 42us/sample - loss: 0.2365 - accuracy: 0.9225 - val_loss: 0.2470 - val_accuracy: 0.9050\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 0s 43us/sample - loss: 0.2285 - accuracy: 0.9220 - val_loss: 0.2412 - val_accuracy: 0.9050\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 0s 43us/sample - loss: 0.2224 - accuracy: 0.9215 - val_loss: 0.2369 - val_accuracy: 0.9100\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 0s 43us/sample - loss: 0.2178 - accuracy: 0.9215 - val_loss: 0.2337 - val_accuracy: 0.9100\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 0s 43us/sample - loss: 0.2142 - accuracy: 0.9215 - val_loss: 0.2313 - val_accuracy: 0.9100\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 0s 44us/sample - loss: 0.2113 - accuracy: 0.9210 - val_loss: 0.2295 - val_accuracy: 0.9100\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 0s 43us/sample - loss: 0.2089 - accuracy: 0.9215 - val_loss: 0.2280 - val_accuracy: 0.9100\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 0s 42us/sample - loss: 0.2070 - accuracy: 0.9225 - val_loss: 0.2269 - val_accuracy: 0.9100\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 0s 43us/sample - loss: 0.2053 - accuracy: 0.9230 - val_loss: 0.2260 - val_accuracy: 0.9100\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 0s 43us/sample - loss: 0.2039 - accuracy: 0.9235 - val_loss: 0.2252 - val_accuracy: 0.9100\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 0s 44us/sample - loss: 0.2027 - accuracy: 0.9235 - val_loss: 0.2247 - val_accuracy: 0.9100\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 0s 43us/sample - loss: 0.2017 - accuracy: 0.9225 - val_loss: 0.2242 - val_accuracy: 0.9100\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 0s 43us/sample - loss: 0.2008 - accuracy: 0.9225 - val_loss: 0.2238 - val_accuracy: 0.9050\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 0s 43us/sample - loss: 0.2000 - accuracy: 0.9230 - val_loss: 0.2235 - val_accuracy: 0.9050\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 0s 43us/sample - loss: 0.1994 - accuracy: 0.9230 - val_loss: 0.2233 - val_accuracy: 0.9050\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 0s 41us/sample - loss: 0.1988 - accuracy: 0.9230 - val_loss: 0.2231 - val_accuracy: 0.9050\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 0s 42us/sample - loss: 0.1982 - accuracy: 0.9225 - val_loss: 0.2229 - val_accuracy: 0.9050\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 0s 42us/sample - loss: 0.1978 - accuracy: 0.9225 - val_loss: 0.2228 - val_accuracy: 0.9050\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 0s 43us/sample - loss: 0.1973 - accuracy: 0.9220 - val_loss: 0.2227 - val_accuracy: 0.9050\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 0s 42us/sample - loss: 0.1970 - accuracy: 0.9220 - val_loss: 0.2227 - val_accuracy: 0.9050\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 0s 46us/sample - loss: 0.1966 - accuracy: 0.9220 - val_loss: 0.2226 - val_accuracy: 0.9050\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 0s 50us/sample - loss: 0.1963 - accuracy: 0.9220 - val_loss: 0.2226 - val_accuracy: 0.9050\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 0s 50us/sample - loss: 0.1961 - accuracy: 0.9220 - val_loss: 0.2226 - val_accuracy: 0.9050\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 0s 51us/sample - loss: 0.1958 - accuracy: 0.9220 - val_loss: 0.2226 - val_accuracy: 0.9050\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 0s 51us/sample - loss: 0.1956 - accuracy: 0.9220 - val_loss: 0.2226 - val_accuracy: 0.9050\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 0s 51us/sample - loss: 0.1954 - accuracy: 0.9220 - val_loss: 0.2226 - val_accuracy: 0.9050\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 0s 50us/sample - loss: 0.1952 - accuracy: 0.9220 - val_loss: 0.2226 - val_accuracy: 0.9050\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 0s 50us/sample - loss: 0.1951 - accuracy: 0.9220 - val_loss: 0.2227 - val_accuracy: 0.9050\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 0s 51us/sample - loss: 0.1949 - accuracy: 0.9220 - val_loss: 0.2227 - val_accuracy: 0.9050\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 0s 51us/sample - loss: 0.1948 - accuracy: 0.9220 - val_loss: 0.2228 - val_accuracy: 0.9050\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 0s 51us/sample - loss: 0.1946 - accuracy: 0.9220 - val_loss: 0.2228 - val_accuracy: 0.9050\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 0s 51us/sample - loss: 0.1945 - accuracy: 0.9225 - val_loss: 0.2228 - val_accuracy: 0.9050\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 0s 50us/sample - loss: 0.1944 - accuracy: 0.9220 - val_loss: 0.2229 - val_accuracy: 0.9050\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 0s 49us/sample - loss: 0.1943 - accuracy: 0.9225 - val_loss: 0.2230 - val_accuracy: 0.9050\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 0s 51us/sample - loss: 0.1942 - accuracy: 0.9220 - val_loss: 0.2230 - val_accuracy: 0.9050\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 0s 50us/sample - loss: 0.1942 - accuracy: 0.9225 - val_loss: 0.2231 - val_accuracy: 0.9050\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 0s 50us/sample - loss: 0.1941 - accuracy: 0.9225 - val_loss: 0.2231 - val_accuracy: 0.9050\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 0s 50us/sample - loss: 0.1940 - accuracy: 0.9230 - val_loss: 0.2232 - val_accuracy: 0.9050\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 0s 50us/sample - loss: 0.1939 - accuracy: 0.9230 - val_loss: 0.2232 - val_accuracy: 0.9050\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 0s 50us/sample - loss: 0.1939 - accuracy: 0.9220 - val_loss: 0.2233 - val_accuracy: 0.9050\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 0s 49us/sample - loss: 0.1938 - accuracy: 0.9230 - val_loss: 0.2233 - val_accuracy: 0.9050\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 0s 49us/sample - loss: 0.1938 - accuracy: 0.9230 - val_loss: 0.2234 - val_accuracy: 0.9050\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 0s 46us/sample - loss: 0.1937 - accuracy: 0.9230 - val_loss: 0.2234 - val_accuracy: 0.9050\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 0s 45us/sample - loss: 0.1937 - accuracy: 0.9230 - val_loss: 0.2235 - val_accuracy: 0.9050\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 0s 47us/sample - loss: 0.1937 - accuracy: 0.9230 - val_loss: 0.2235 - val_accuracy: 0.9050\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 0s 51us/sample - loss: 0.1936 - accuracy: 0.9225 - val_loss: 0.2236 - val_accuracy: 0.9050\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 0s 46us/sample - loss: 0.1936 - accuracy: 0.9230 - val_loss: 0.2236 - val_accuracy: 0.9050\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 0s 43us/sample - loss: 0.1936 - accuracy: 0.9230 - val_loss: 0.2237 - val_accuracy: 0.9050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe3601ca240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=16, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got `train accuracy = 0.9230` and `validation accuracy = 0.9050`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
